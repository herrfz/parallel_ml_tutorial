{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Predictive Modeling with heterogeneous data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/images/predictive_modeling_data_flow.png\">"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading tabular data from the Titanic kaggle challenge in a pandas Data Frame"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us have a look at the Titanic dataset from the Kaggle Getting Started challenge at:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted\n",
      "\n",
      "We can load the CSV file as a pandas data frame in one line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!curl -s https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv | head -5\n",
      "with open('titanic_train.csv', 'r') as f:\n",
      "    for i, line in zip(range(5), f):\n",
      "        print(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
        "\n",
        "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n",
        "\n",
        "2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n",
        "\n",
        "3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n",
        "\n",
        "4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = pd.read_csv('https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv')\n",
      "data = pd.read_csv('titanic_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas data frames have a HTML table representation in the IPython notebook. Let's have a look at the first 5 rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>        A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>         PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td>  C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>                            Heikkinen, Miss. Laina</td>\n",
        "      <td> female</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> STON/O2. 3101282</td>\n",
        "      <td>  7.9250</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td> female</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>           113803</td>\n",
        "      <td> 53.1000</td>\n",
        "      <td> C123</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                          Allen, Mr. William Henry</td>\n",
        "      <td>   male</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>           373450</td>\n",
        "      <td>  8.0500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "2            3         1       3   \n",
        "3            4         1       1   \n",
        "4            5         0       3   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "2                             Heikkinen, Miss. Laina  female   26      0   \n",
        "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
        "4                           Allen, Mr. William Henry    male   35      0   \n",
        "\n",
        "   Parch            Ticket     Fare Cabin Embarked  \n",
        "0      0         A/5 21171   7.2500   NaN        S  \n",
        "1      0          PC 17599  71.2833   C85        C  \n",
        "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3      0            113803  53.1000  C123        S  \n",
        "4      0            373450   8.0500   NaN        S  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "PassengerId    891\n",
        "Survived       891\n",
        "Pclass         891\n",
        "Name           891\n",
        "Sex            891\n",
        "Age            714\n",
        "SibSp          891\n",
        "Parch          891\n",
        "Ticket         891\n",
        "Fare           891\n",
        "Cabin          204\n",
        "Embarked       889\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data frame has 891 rows. Some passengers have missing information though: in particular Age and Cabin info can be missing. The meaning of the columns is explained on the challenge website:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted/data\n",
      "\n",
      "A data frame can be converted into a numpy array by calling the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(data.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['PassengerId',\n",
        " 'Survived',\n",
        " 'Pclass',\n",
        " 'Name',\n",
        " 'Sex',\n",
        " 'Age',\n",
        " 'SibSp',\n",
        " 'Parch',\n",
        " 'Ticket',\n",
        " 'Fare',\n",
        " 'Cabin',\n",
        " 'Embarked']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(891, 12)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
        "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
        "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
        "       ..., \n",
        "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
        "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
        "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However this cannot be directly fed to a scikit-learn model:\n",
      "\n",
      "\n",
      "- the target variable (survival) is mixed with the input data\n",
      "\n",
      "- some attribute such as unique ids have no predictive values for the task\n",
      "\n",
      "- the values are heterogeneous (string labels for categories, integers and floating point numbers)\n",
      "\n",
      "- some attribute values are missing (nan: \"not a number\")"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicting survival"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of the challenge is to predict whether a passenger has survived from others known attribute. Let us have a look at the `Survived` columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survived_column = data['Survived']\n",
      "survived_column.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`data.Survived` is an instance of the pandas `Series` class with an integer dtype:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(survived_column)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "pandas.core.series.Series"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `data` object is an instance pandas `DataFrame` class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Series` can be seen as homegeneous, 1D columns. `DataFrame` instances are heterogenous collections of columns with the same length.\n",
      "\n",
      "The original data frame can be aggregated by counting rows for each possible value of the `Survived` column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.groupby('Survived').count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Survived</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 424</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td>  68</td>\n",
        "      <td> 549</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 290</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 136</td>\n",
        "      <td> 340</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "          PassengerId  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
        "Survived                                                                    \n",
        "0                 549     549   549  549  424    549    549     549   549   \n",
        "1                 342     342   342  342  290    342    342     342   342   \n",
        "\n",
        "          Cabin  Embarked  \n",
        "Survived                   \n",
        "0            68       549  \n",
        "1           136       340  "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(survived_column == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.61616161616161613"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this the subset of the full passengers list, about 2/3 perished in the event. So if we are to build a predictive model from this data, a baseline model to compare the performance to would be to always predict death. Such a constant model would reach around 62% predictive accuracy (which is higher than predicting at random):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas `Series` instances can be converted to regular 1D numpy arrays by using the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = survived_column.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([0, 1, 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training a predictive model on numerical features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` estimators all work with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
      "\n",
      "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "numerical_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately some passengers do not have age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       714\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use pandas `fillna` method to input the median age for those passengers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "median_features = numerical_features.dropna().median()\n",
      "median_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "Fare      15.7417\n",
        "Pclass     2.0000\n",
        "Age       28.0000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features = numerical_features.fillna(median_features)\n",
      "imputed_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array = imputed_features.values\n",
      "features_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([[  7.25  ,   3.    ,  22.    ],\n",
        "       [ 71.2833,   1.    ,  38.    ],\n",
        "       [  7.925 ,   3.    ,  26.    ],\n",
        "       ..., \n",
        "       [ 23.45  ,   3.    ,  28.    ],\n",
        "       [ 30.    ,   1.    ,  26.    ],\n",
        "       [  7.75  ,   3.    ,  32.    ]])"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "dtype('float64')"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take the 80% of the data for training a first model and keep 20% for computing is generalization score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "(712, 3)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "(179, 3)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "(712,)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(179,)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a simple model from sklearn, namely `LogisticRegression`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "logreg.fit(features_train, target_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
        "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "          verbose=0)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted = logreg.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "accuracy_score(target_test, target_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This first model has around 73% accuracy: this is better than our baseline that always predicts death."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model evaluation and interpretation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpreting linear model weights"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = numerical_features.columns\n",
      "feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "Index(['Fare', 'Pclass', 'Age'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([[ 0.0043996 , -0.80916725, -0.03348064]])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(len(feature_names))\n",
      "plt.bar(x, logreg.coef_.ravel())\n",
      "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEJCAYAAABv6GdPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10d826470>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, survival is slightly positively linked with Fare (the higher the fare, the higher the likelyhood the model will predict survival) while passenger from first class and lower ages are predicted to survive more often than older people from the 3rd class.\n",
      "\n",
      "First-class cabins were closer to the lifeboats and children and women reportedly had the priority. Our model seems to capture that historical data. We will see later if the sex of the passenger can be used as an informative predictor to increase the predictive accuracy of the model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Alternative evaluation metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to see the details of the false positive and false negative errors by computing the confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "cm = confusion_matrix(target_test, target_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The true labeling are seen as the rows and the predicted labels are the columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_confusion(cm):\n",
      "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.binary)\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.set_cmap('Blues')\n",
      "    plt.colorbar()\n",
      "\n",
      "    target_names = ['not survived', 'survived']\n",
      "\n",
      "    tick_marks = np.arange(len(target_names))\n",
      "    plt.xticks(tick_marks, target_names, rotation=60)\n",
      "    plt.yticks(tick_marks, target_names)\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    # Convenience function to adjust plot parameters for a clear layout.\n",
      "    plt.tight_layout()\n",
      "    \n",
      "plot_confusion(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAEaCAYAAACB7ptqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10d8abdd8>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can normalize the number of prediction by dividing by the total number of true \"survived\" and \"not survived\" to compute false and true positive rates for survival (in the second column of the confusion matrix)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cm.astype(np.float64) / cm.sum(axis=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.89090909  0.17391304]\n",
        " [ 0.32727273  0.47826087]]\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can therefore observe that the fact that the target classes are not balanced in the dataset makes the accuracy score not very informative.\n",
      "\n",
      "scikit-learn provides alternative classification metrics to evaluate models performance on imbalanced data such as precision, recall and f1 score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.73      0.89      0.80       110\n",
        "    survived       0.73      0.48      0.58        69\n",
        "\n",
        " avg / total       0.73      0.73      0.72       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to quantify the quality of a binary classifier on imbalanced data is to compute the precision, recall and f1-score of a model (at the default fixed decision threshold of 0.5)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the posterior probability of the outcome given the input features using the `predict_proba` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_proba = logreg.predict_proba(features_test)\n",
      "target_predicted_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([[ 0.75263264,  0.24736736],\n",
        "       [ 0.75824771,  0.24175229],\n",
        "       [ 0.58542437,  0.41457563],\n",
        "       [ 0.25224882,  0.74775118],\n",
        "       [ 0.75817844,  0.24182156]])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
      "\n",
      "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(target_test, target_predicted_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(target_test, target_predicted_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucVfP6wPHP03SvyUylotsQUiikcomKdJGDQ4qIHNdz\n3OUu6iB+OcRxV5Q6Dh0pKpdCDFGkmuleRLpHNzW6TTXP74+19rRnz549a6a999p75nm/Xvs1e92f\ntWZmfdf3sr5fUVWMMcaYgAp+B2CMMSaxWMJgjDGmAEsYjDHGFGAJgzHGmAIsYTDGGFOAJQzGGGMK\nsITBFEtEForIWX7HkShE5AERGeHTsd8Ukcf8OHa0icgVIjK1lNva32QMWcKQZETkVxHZKSI5IrJB\nRP4jIrVieUxVPV5Vv47lMQJEpIqIPCkiK93z/FFE7o7HsYuIp5OIrA6ep6pPqur1MTqeiMhtIrJA\nRP4UkdUi8q6IHB84vPvxlYgMFpH/HMw+VPW/qtrNw7EKJYbx/JssjyxhSD4KnK+qqUBr4ARgoL8h\nlZyIVCxi0TigM9ADqAn0A24QkX/HIAYREYn2fg/Sv4HbgFuBdOAY4APgvGgfSERSor3PZDi28UBV\n7ZNEH2AFcHbQ9FPAR0HTpwIzgK1ANtAxaFltYBSwFtgCvB+07Hx3/a3At8AJQct+Bc4GDgd2AulB\ny04CNgIp7vTfgMXu/qcATYLWzQP+AfwE/Bzm3M4BdgENQ+a3A/YBR7rTmcCTwPfANpwbZ7rHa5AJ\nPO6e406gGXCNG/N24GfgBnfdGm48+4Ecd/lhwGDgP+46Ge55XQWsdK/Fg0HHqwaMdq/HYuBeYHUR\nv9uj3fM8JcLvfxTwIvChG893geviLv83sMq9LrOBDkHLBgPvAf9xl/8NaAvMdK/VOuAFoFLQNscB\nnwGbgQ3AA0A3YA+Q616XLHfdQ4A33P2sAR4DKrjL+rvXfBiwyV3WH5juLhfgWeA3N7b57rFvcI+z\nxz3WxKC/yXPc7ynAg8By95rMBhr5/b+azB/fA7BPCX9hTsIQ+Ido5P4DPeJON3T/6bq7013c6Tru\n9EfAO+4/cEXgTHf+Se4/ZFv3H/Qq9ziVgo55tvt9GnBdUDz/Al52v1+Ic9NvjpMbfQj4NmjdPGAq\nkAZUCXNu/wd8WcR5/wpc737PdG88LYHqgZudx2uQ6e6rhRtjRZyn8SPc5WcBO4CT3OmOhNzIgUEU\nThheA6oArYDdQPPgc3KveUP397WqiHO8CVhRzO//Tfd8TnFviG8B7wQtvwInp1EBuAtYD1R2lw3G\nucle4E5XBU7GSXgrAE1xEq/b3eWp7vZ3ApVxcnDtgq7BmJDY3gdewUkMD8VJuAOJbH9gL3Cze6yq\nFEwYuuHc0Gu5082BBu73UcCjYf4PAn+T97jX9Wh3+gSgtt//q8n8saKk5CPAByKyHefJ8GecJ2CA\nK4GPVXUKgKp+jvPP1lNEDgO6Azep6jZV3aeq093tbgBeU9Uf1DEG5wnt1DDHfxu4HJyiGKCPOw+c\nG9uTqrpMVfNwnupPFJHGQds/qap/qOqeMPuui/NUGs56dzk4xWljVHWxqu4EHgZ6i0iFSNcgaNs3\nVXWJqua51+FjVV3hrv818Clwprt+uKKmcPP+qap7VHU+MA+nmA/gUuAJ95qvxXmiL6r4qk6E8w9Q\nYIKqzlbV/cB/gRPzFzrl9lvdcxuGk1g1D9p+hqpOctfdrapzVXWWu/5KYDhOYghOLnKdqj6rqrmq\n+qeqzgq6BvnnISL1cYr/7lTVXaq6EXgOuCzo2OtU9SX3WLtDzmsvTkLUQkQquH9DwdciUpHfdcBD\nqvqTe14LVHVLhPVNMSxhSD4KXKiqtYBOOEU8p7jLmgKXisjWwAc4A2gANAa2qOq2MPtsCgwI2a4R\nTtFRqAnAaSLSAOfpOk9Vvwnaz7+D9rHZnd8waPsCFbkhNuIU1YRzOM6Tcrj9rAIq4SQcka5B2BhE\npIeIfCcim931z8O5SZdE8E1sJ87TdSDu4OOtibCPzRR9/sF+C/q+K+hYiMjdIrJYRP5wz+UQDiSo\nhY4vIseIyIcisl5EtgFDOHDujYFfPMQDznWvBKwPuu6v4uQcAor83avqFzhFZC8Bv4nIayKS6vHY\njXAekEyUWMKQxNyn2xeAoe6sVThFHOlBn1RVfQrnn7K2iBwSZlergCEh29VU1f+FOeZWnCfqPkBf\nnKKp4P3cELKfGqr6XfAuIpzS50B7EWkUPFNE2uP8838RNLtJyPe9OAlLpGtQKAYRqQKMx6mrqaeq\n6cDHHHhCDRdvSVoFrce5wQY0LmpFnGK6RiLSpgT7zyciZ+IUq1yqqmnuuWyj4NN2aOyv4BQfHaWq\nh+AU/wXuC6uAI4s4XF7I9GqcXGadoOt+iKqeEOHYBajqC6p6Ck4R4THuuRS7nXvso4pZx5SAJQzJ\n7zmgnXvzfAv4i4h0FZEUEanqNrdsqKrrgU+Al0UkTUQqBbUDHwHcJCLt3IY6NUSkp4jULOKYbwNX\nA5dwoBgJnCfEB0WkJYCIHCIil3o9EVWdhnNzHC8iLd1zOBWnsvRlVQ08FQpwpYi0EJHqwKPAOFXV\nSNcg6FDBN8rK7mcTkCciPYCuQct/A+qENAkuSUumd4EH3GveELiFIm50blHIy8A7ItJRRCq78V8m\nIvd5OHYqTuX1JnfbR4DimjLXxKnU3SkixwJ/D1r2EXCYiNzuNiNOFZF27rLfgIxAqy737+tTYJi7\nXgURaSYe3zUQkVNEpL2IVMLJce3GqfQPHKuoBArgdeAxETnK/fttJSK1vRzXhGcJQ5JT1U04rV7u\nU9U1OBXADwK/4zzxDeDA77kfzpP1Upx/ttvcfcwBrsfJym/BqUC+iqKf1CbhPKGtV9UFQbF8gJN7\nGesWSyzAqVTMX8XDKV2CU1k7BeeG9R/gdVW9NWQ//8GpiF2Pc2MPnEtR1yDsU7Oq5rjbvuue++XA\nxKDlS3FyRb+IyBa3rib0XYJI5/UoTvHNCpwb5zicCuCwVPU2DhSpbMVpaXMhzjUPHCv0eIHpKe7n\nR5wK9l045x+8Xui2d+Pk/Lbj1C+MDazjXptzgb/gXOcfcYovcc8DYLOIzHa/X4Xzuwi0ShvHgSK8\nouIOzKvlHn+LG/smnIYN4LR0aukWUU2gsGE4v79PcXJII3Aqt00pifOQFaOdi4zEqfT7PSRLGbzO\n8ziVVjuB/qqaFbOATJkgIl/iFBeN9DuWkhKRvwO9VbWz37EYU5RY5xhG4bSECUtEzsMp2zwap2XM\nKzGOx5QdifZiWlgi0kBEznCLVprjNCF93++4jIkkpgmD2xxya4RVLsApBkFVvwfS3GZvxhTH924h\nPKqMU/eyHaf+5AOcegRjElZR3RLES0MKN+VrRMHmeMYUkEzFMKq6CueFK2OSRiJUPocWCSTLk6Ax\nxpRJfucY1lKwXXcjd14BImKJhTHGlIKqlrg+zu8cwyScJm647dX/UNWwxUiR+vUoT59Bgwb5HkOi\nfOxa2LWwa3HgM3fuXFq1akXPnj1Zu3YtHTuW/nk6pjkGEXkHp9+VuuL0aT8I57V5VPU1Vf1YRM4T\nkeU4HZddE8t4jDEm0ezbBzfcAH/+Wfp9/Pjjsyxd+iStWj1NtWr9uOMOYdGi0u8vpgmDql7uYZ1b\nYhmDMcYksp074Z13YPTo0u9j6dK21KuXTe3aB7o369MHevUq3f78rmMwJdSpUye/Q0gYdi0OsGtx\nQDJei0qVoHfvg9lDh2iFAsT4zedoERFNhjiNMWbHDnjzTdi/v9hVAdi9Gx5/HLZvj34sIoKWovLZ\ncgzGGBNF2dnOjf5Sz91HwoMPFr9Obm4uQ4YMIS0tjTvvvLP0AXpgCYMxxkTZkUfC889Hb39ZWVn0\n79+fxo0bM3z48OjtuAiWMBhjTAS7d8Pixd7XX7YsescO5BJeeeUVnn76afr164fb03lMWcJgjDER\nvPUW3H8/NGlS/LoBZ58dnWPfcccdrFq1iuzsbA4/PNyAirFhlc/GGBPBq6869Qavvhr/Y+fk5FCz\nZs1S5xKs8tkYY8qY1FSvw15Hl99dYhhjTLmXm5vL5s2b/Q4jnyUMxhjjo6ysLNq2bcvLLyfOMB2W\nMBhjjA9yc3MZNGgQ3bp1Y8CAAQwcONDvkPJZHYMxpkxThSeegK++Kt32q1dD5ygPDRX8XkK8Wxx5\nYa2SjDFl2uDB8P77MHQoVChlGcnxx0M0793Dhg2jbt26MX8vobStkixhMMaUWc8+C6+8AtOnQ/1y\nOJq8NVc1xpRLkydDVlbh+Rs3wqRJ5TdROBhW+WyMSWpPPw3LlzsD3gR/ateGL74o2RvL0ZaVlcWX\nX37pXwClZDkGY0zSu/Za6NjR7ygOCO7jKJGaoXplCYMxZdRvv3FQwzsmi61b/Y6goERvceSFJQzG\nlFFDhsCUKdCokd+RxFb9+tC0qd9ROF588UUeffTRuPaEGgvWKsmYMurmm6FlS+eniY85c+Zw2GGH\nJUwuwVolGWOMz9q0aeN3CFFhrZKMMcYUYDkGY4wpgUCLowoVKjBo0CC/w4kJyzEYY4xHgZ5Q58yZ\nw/XXX+93ODFjOQZjkty//gXvvVd4/ooV8Nhj8Y+nLPJr7GW/WMJgTJL7/nu46KLw4wy3ahX/eMqi\nhx56iCVLliTtewkl5bm5qohUBVRV98Q2pLDHtuaqxhShVy+47DLnp4mNXbt2UbVq1aTLJUS9uaqI\nVAAuAi4HTsepjxAR2Q/MBP4LfGB3bGPib/x4mDHD+T5vnpMwmNipVq2a3yHEVZE5BhH5GpgOTAKy\nAzkFEakCnARcAHRQ1bNiHqTlGIwpoEcPaNgQWrQAEejXDw491O+okl9ubi5btmyhQYMGfocSFbF4\nwe3ccMVG7rzvgO/cRMIY44NLLnESCBMdgT6OevbsyRNPPOF3OL4qsrlqUA5hmIgcF2kdY4xJVqFj\nLw8ZMsTvkHznpVXSEmC4iFQCRgLvqOq22IZljDGxVxZ6Qo2FYl9wU9URqnoGcBWQASwQkbdFJMrD\nYxtjTHzNmTOHAQMGMHnyZEsUgnh6j0FEUoBjgRbARmAecJeI3KSqfWIYnzHlzs6dsGNH5HVyc+MT\nS1l33XXX+R1CQio2YRCRZ4G/AF8AQ1R1lrtoqIgsi2VwxpRHHTo4by1XjPDfWaEC1KsXv5hM+eIl\nxzAfGKiq4Z5h2kc5HmPKvZ07YeZMOPZYvyMpO7Kysli7di3nn3++36EkBS+d6PULTRREZBqAqv4R\naUMR6S4iS0XkJxG5L8zyuiIyRUSyRWShiPQvSfDGGBNJcIujHcWVz5l8kd58rgZUB+qKSO2gRbWA\nhsXt2K2XeBHoAqwFfhCRSaq6JGi1W4AsVX1AROoCy0TkLVXdV4pzMSbh5OXBaafBHxEfoQpasQIq\nV45dTOWFtTgqvUhFSTcCtwOHA3OC5ufg3PCL0w5Yrqq/AojIWOBCnOavAeuBQDdftYDNliiYsmT/\nfpgzBxYt8r5N5cqQkRGzkMqF4cOHM3DgwHLRE2osFNuJnojcqqovlHjHIr2Abqp6vTt9JdBeVW8N\nWqcCTqX2MUAq0FtVPwmzL+sSwySlvXuhenXnp4mfxYsXk5aWVu5zCbHoRO9sVf0CWCciF4cuV9UJ\nxezby538QZx+mDqJSDPgMxFprao5oSsOHjw4/3unTp3o1KmTh90bEx979sBdd8Hu3QXn5+X5E095\n17JlS79D8EVmZiaZmZkHvZ9Inej9U1UHicibhLnJq+o1EXcsciowWFW7u9MPAHmqOjRonY9xmsB+\n605PA+5T1dkh+7Icg0loa9fCccfBM88UXlanjjNegokNVbWioiKUNsfgpSipYmnK/UWkIrAMOAdY\nB8wCLg+ufBaRYcA2Vf2niNTHqctopapbQvZlCYNJaGvXQrt2zk8TH4FR1XJychg2bJjf4SSkWPSu\nGvCLiEwB/gd84fUOrar7ROQWYCqQAryhqktE5EZ3+WvAE8AoEZmH03T23tBEwZhEkpsL//sf7At5\nVNq61Z94yqvgFkfDhw/3O5wyx0uOoQZwPnAZcDIwGfifqk6PfXj5MViOwSSEuXOhSxe48MLCy5o1\ng4ED4x9TeVLexl4+WDHLMbgvt/0P+J+IpAPPA5k4uQBjyp2MDBg1yu8oyqcnnniCOXPm2HsJMea1\nE71OQB+gO/AD0DuGMRnji7w8+OUXiJQ5XbUqfvGYwh588EEqVapkuYQY89KJ3q9ANk6u4R5V/TPW\nQRnjh48+csZOLu5B9Mwz4xOPKayyvRIeF15yDK1UdXvMIzHGZ7m50L07jB/vdyQmNzeXDRs20KRJ\nE79DKZeK7EQvqNO7ISLyQsjn+TjFZ4wpZ7Kysmjbti3PPfec36GUW5FyDIvdn3Mo+IKb4O2tZmNi\nZvBgeOWV6O5z9274y1+iu0/jXbgWR8YfRSYMqjrZ/bpTVd8NXiYiVvlsfLViBTz0EPSJ8viBaWnR\n3Z/xxnpCTSxe6hgeAN71MM+YuDrkEKhf3+8oTDT89NNPDBgwwN5LSBCROtHrAZwHNHTrFAK/rVTA\n+oo0B23wYFiwoHTb/vADnHNOVMMxPurd2wohEkmkTvRaAycBjwIPcyBh2A58qapx6wTA3nwum5o3\nh5tvhobFDvsUXpcuTq7BGBNeLDvRq6SqvuYQLGEom5o3h0mTnJ+mfMjKymLZsmVcdtllfodSLpQ2\nYYjUXHWc+3WuiCwI+cwvdaTGmHIneOzlPBukIuFFqny+3f1pDfiMMaVmLY6ST5E5BlVd537dCKx2\nx26ugjNGs/U6b4wp1ptvvkm3bt0YMGAAkydPtkQhSXhprjod6OD2rDoVpxO9PsAVsQzMJJ+lS+HP\nEvSkFToMpil7zjrrLMslJCEvCYOo6k4RuRZ4WVWfcgfWMSbf3r1w/PFw4onet2nYEOrWjV1Mxn9H\nHnmk3yGYUvDa7fZpODmEa91ZRRZBmfJJFSpUgNmzi1/XlE029nLZ4eUGfwfOm87vq+oiEWkGfBnb\nsIwxySLQ4uj666/3OxQTJcW+x5AI7D0Gf61bB8ce63RLXRRVqFULNm6MX1zGf6FjL1tdQmKJ2dCe\nItIcuBvICFpfVfXskh7MJKecHKdPouK6r0ixwV7LDRt7uWzzUscwDngFeB3YH9twTKKqUAGqVvU7\nCpMoXnjhBRt7uQzz0iXGHFVtE6d4iorBipLiYOVKuOEG2B+S/O/YAdu2weLF4bcz5c++fftISUmx\nXEKCi1lREjBZRG4GJgB7AjNVdUtJD2YS28qVTn3Cs88WXmYPhSZYxYqeGjSaJOXlt9sfZ8S2u0Pm\nHxH1aIzv0tOdXkuNAacuYeXKlRx99NF+h2LiqNiEQVUz4hCHKaHZs+HDD6O7z5Uro7s/k9wCLY7O\nOOMMXn75Zb/DMXFU7HsMIlJDRB4WkRHu9NEicn7sQzORjB0LM2ZEd59Nm8KAAdHdp0k+ubm5PPLI\nI3Tr1o27776bl156ye+QTJx5KUoaBcwBTnen1wHvAVF+XjUl1bUr3B1awGfMQcjKyuLqq6+madOm\n1uKoHPOSMDRT1d4ichmAqu6wlgj+WL8eFi1yvq9cCQ0a+BuPKXs2bNjAPffcw5VXXmktjsoxLwnD\nHhGpFphwu8TYE2F9EyOPPw7TpkGjRs70SSf5G48pe3r06OF3CCYBeEkYBgNTgEYi8jZwBk5LJRNn\neXlw++3w97/7HYkxpiwrtvJZVT8FLgGuAd4G2qiqdaJnTBKbO3cur7/+ut9hmAQVacznDBFJA1DV\nTcBOoCtwlYhUjlN8xrVjB3z/PaSl+R2JSWaBFkfdu3enWrVqxW9gyqVIOYZ3geoAInIiTp9JK4ET\nAWvUHEd79sBf/wqtW0OfPn5HY5LV3LlzOeWUU8jKyiI7O5srrrBBGE14keoYqgaN+3wl8IaqPiMi\nFQAbwS1O9u2Dyy93urQeMcLpzM6Ykvrvf//LnXfeyTPPPGMtjkyxIiUMwX855+AM1oOq5tkfVWz9\n3//Be+8537dvhyOOgEmTwLqnMaXVuXNney/BeBbpVvOliIwD1gNpwBcAInI4Hpurikh34DkgBXhd\nVYeGWacT8CxQCdikqp1KEH+Z9MMPcOmlcM45znSrVlDZanXMQbAEwZREpIThDqAP0ADooKqB8bvq\nAw8Vt2MRSQFeBLoAa4EfRGSSqi4JWicNeAnopqprRMSGhncddRSccorfUZhklJeXRwUrczQHIVLC\noKr6TpiZWYHvEnmghHbAclX91V13LHAhsCRonb7AeFVd4+57U8nCLztGjYJ5bs3NvHnQt6+/8Zjk\nk5uby+OPP86PP/7I2LFj/Q7HJLFIjxWZInKPiBwTukBEmovIfcBXEbZvCKwOml7jzgt2NFBbRL4U\nkdki0s9r4GXJc8/Bk09CRobzufVW6NjR76hMMgm0OJo7dy7Dhg3zOxyT5CLlGLoCVwAvicjxQA5O\nhXRNYCHwX5xioqJ4GXKtEnAyTuV2dWCmiHynqj952LZMGDnSSRi+/hqaNPE7GpNsbOxlEwtFJgyq\nugcYCYx06wsC5f+bVNXL2M9rgcZB041xcg3BVrv72wXsEpGvgdZAoYRh8ODB+d87depEp06dPISQ\n2MaPh4EDITPTEgVTOiNHjrSxl02+zMxMMjMzD3o/xY75XOodi1QEluHkBtYBs4DLQyqfj8WpoO4G\nVAG+B/qo6uKQfZXJMZ/PPBPuvRf+8he/IzHJKi8vDxGxXIIJK5ZjPpeKqu4TkVuAqTjNVd9Q1SUi\ncqO7/DVVXSoiU4D5QB4wIjRRKMtUnaE0jSkta31kYiGmr0yp6ifAJyHzXguZfhp4OpZx+OHPP53+\njSLJzY283JiA3NxcfvrpJ4477ji/QzHlQMSEwS0O+kxVO8cpnjLjxBPhjz8gJaXodVJSoK69uWGK\nkZ2dTf/+/WnTpg1vvPGG3+GYciBiwuAWB+WJSJqq/hGvoMqCXbuc9xEahjbQNcajcC2OjIkHL0VJ\nO4AFIvKZ+x2cl99ui11YxpRv8+fP56qrrqJRo0bW4sjEnZeEYYL7CTQLEry9o2CMKaVt27Zx1113\n2XsJxheemquKSBUg8Ab0UlXdG9OoCh8/6ZqrNmwIs2ZZUZIxxj8xa67q9n46GmeQHoAmInK1qkbq\nDsMYY0yS8tIIehjQVVXPUtWzcLrKeDa2YRlTPmRnZ/Pcc8/5HYYxBXhJGCqq6rLAhKr+SIzffzCm\nrMvNzWXQoEF07dqVOnXq+B2OMQV4ucHPEZHXgbdwKp6vAGbHNCpjyrDAewnW4sgkKi85hr/jjKFw\nG3ArsMidZyJIsrpyEyfjx4+na9eu3HXXXUyePNkSBZOQYtaJXjQlW6ukZ56BESOcF9yqVPE7GpNI\nNm/ezJ49eyxBMHGRcJ3olVcjRsALL8D06ZYomMKsPsEkA0sYomjsWBg82BlfoXHj4tY2Zd3+/ftJ\nidRZljEJynOfvSJSPZaBlAW33goTJ8LRR/sdifFToMXRBRdc4HcoxpRKsQmDiJwuIotxBt1BRE4U\nkZdjHlkS2rsXjjrK7yiMn7Kzs2nXrh1z5sxhxIgRfodjTKl4yTE8B3QHNgGoajZgQ9UbEyT4vQRr\ncWSSnac6BlVdFdKR177YhJN8jjsOfv/d+b5zJ1Sq5G88xh/jxo2zsZdNmVFsc1UReQ+nC4wXgfY4\n7zOcoqqXxT68/BgStrlqxYqwerXzs0oVqFXL74iMHwJ/n9YTqkkkpW2u6iVhOBT4N9AF583nT4Hb\nVHVzaQItjURPGHbvdn4aY0wiKW3C4KWO4RhV7auq9VT1UFW9Aji25CEak/xyc3OZO3eu32EYE1Ne\nEoYXPc4zpkwLtDgaNmyY36EYE1NFFoCIyGnA6cChInIXTjESQColeP/BmGRnYy+b8iZSyXhlnEQg\nxf0ZsB3oFcugEpkqvPEGbNvmTOfl+RuPia0FCxbQr18/6wnVlCteKp8zVPXX+IRTZAwJU/m8Zw9U\nrw533OFMp6XBwIFgjVHKpuzsbObPn29jL5ukFMtWSfWAe4GWQDV3tqrq2SWOspQSLWGoVcv5aYwx\niSyWvav+F/gfcD5wI9Af2FjSAyW7BQucF9hyc/2OxBhjYstLjmGuqp4sIvNVtZU7b7aqnhKXCPE/\nx7BtG9SpA23aONP168OkSb6FY2IgOzubyZMn8/DDD/sdijFRE8v3GALPyBtE5HwRORlIL+mBktn+\n/U7x0fffOx9LFMqO4D6OmjZt6nc4xiQEL0VJQ0QkDRgAvADUAu6MaVTGxIGNvWxMeKUa2lNE2qnq\nrBjEU9TxYlaU9NNP0Lo17IvQLaAqNGoEK1bEJATjg48++ohrrrkm/70Ea3FkyqKot0oSkQrAX4Fm\nwEJV/VhETgGeAOqp6okHE3CJgoxhwjBnDlx3nVNEFElKivMxZUNOTg45OTmWSzBlWixaJQ0HjgBm\nAQNF5FqcPpIeAiaWKsoEVaECVK7sdxQmnlJTU0lNTS1+RWPKoUgJw6lAK1XNE5GqwAagWTx7VY2m\nZcvg5psLv6m8fbvlBMq6vXv3UskGyjDGs0gJw15VzQNQ1d0isiJZEwWAn392EoH/+7/Cyxo3jn88\nJvYCfRxlZmaSmZlp9QjGeBQpYThWRBYETTcLmtbAOw3JpG5dODtu72sbPwW3OHrnnXcsUTCmBCIl\nDC3iFkWMrFsHr73mtCr66Se/ozHxEK4nVEsUjCmZIhOGaHScJyLdgedwemh9XVWHFrFeW2Am0FtV\nJxzscQO+/Rbeew/69IEWLaB9+2jt2SSqqVOn2tjLxhykUr3H4GnHIinAMpwhQdcCPwCXq+qSMOt9\nBuwERqnq+DD7KlVz1XHj4N13nZ+mfLCxl405IJZdYpRWO2C5qv6qqnuBscCFYda7FXiPctgxn4k+\nEbFEwZiD5ClhEJHqItK8hPtuCKwOml7jzgveb0OcxOIVd1Zi9K1tEl5ubi4zZszwOwxjyqRiEwYR\nuQDIAqa60yeJiJdu5Lzc5J8D7nfLiYQDw4caU6TA2MvPPvsssSoKNaY889KJ3mCgPfAlgKpmiciR\nHrZbCwRIG7LAAAAgAElEQVS/IdAYJ9cQrA0w1s361wV6iMheVS2U8AwePDj/e6dOnejUqZOHEExZ\nYi2OjIks8M7OwfIyHsP3qtpeRLJU9SR33vzi3mMQkYo4lc/nAOtwutYoVPkctP4oYHK4VklW+WwW\nL15M3759adSoEcOHD7cWR8Z4EMsR3BaJyBVARRE5GrgNKLZwV1X3icgtOEVQKcAbqrpERG50l79W\n0mBN+VW5cmXuuusuyyUYEwdecgw1cDrO6+rOmgo8pqq7YxxbcAyWYzDGmBKKZY6huao+CDxY8rCM\nMcYkGy/NVYeJyFIReUxEjo95RKZcy87O5p577rHWRsb4qNiEQVU7AZ2BTcBrIrJARGzEdBNVwWMv\nn3DCCX6HY0y55ukFN1Vdr6r/Bm4C5gGPxDQqU64E3ksI9HF01VVXWQWzMT7y8oJbSxEZLCILgRdx\nWiQ1LGYzYzyZNm0aXbt25a677mLy5MnWDNWYBOCl8nkkTj9H3VR1bYzjMeVMhw4drCdUYxJMsQmD\nqp4aj0BM+VSlShVLFIxJMEUmDCIyTlUvDRnFLSApR3Az/tq9ezdVq1b1OwxjTDEi5Rhud3+eT+HO\n7awtofEs0MfRRx99xA8//GAVy8YkuCIrn1V1nfv1H+6YCvkf4B9xic4kveAWR5MmTbJEwZgk4KW5\natcw886LdiCmbAl+L8FaHBmTXCLVMfwdJ2fQLKSeIRX4NtaBmeQ2c+ZM5s6day2OjElCkeoY3gY+\nAf4PuI8D9Qw5qro51oGZ5NaxY0c6duzodxjGmFKIlDCoqv4qIjcTUtksIrVVdUtsQyudL76A6693\nvv/5J3Tp4m88xhiTbCIlDO8APYE5hG+FdERMIjpIq1ZB69bwr3850/Xr+xtPWZebm8v06dM555xz\n/A7FGBMlRSYMqtrT/ZkRt2iipFYtaNbM7yjKvuzsbPr3788RRxxB586dqVDBU9dbxpgE56WvpDNE\npKb7vZ+IDBORprEPzSSq0BZHEyZMsETBmDLES19JrwKtRaQ1cBfwBjAGsJrFcmjp0qVcdtllNGrU\nyFocGVNGeXnM26eqecBFwEuq+iJOk1VTDtWqVYsBAwbYewnGlGFexnz+GpgCXAOcCWwEslU1bqOp\nFDfm8/r18OGHzvdv3Tcs3nwz9nEZY0wiK+2Yz15yDH2APcDfVHUDzlgM/yrpgWJpwgR49lmYNQsq\nVYKLL/Y7ImOMSV7F5hgARKQB0Ban2eosVf091oGFHD9ijuGll2DxYueniY7s7GxeffVVXn75ZatY\nNiZJxSzHICK9ge+BS4HewCwRubTkIZpkENzi6PTTT7dO74wph7y0ShoItA3kEkTkUGAaMC6WgZn4\nC7yXYC2OjCnfvJQRCE6Fc8BmCo/PYJLcjBkzrCdUYwzgLccwBZgqIm/jJAh9cDrXM2VI+/btmT9/\nPg0aNPA7FGOMz7yM+XyPiFwMdHBnvaaq78c2LBNvKSkpligYY4DI4zEcg9Ms9ShgPnCPqq6JV2Am\ndnbs2EGNGjX8DsMYk6Ai1TGMBD4ELgHmAs/HJSITM4EWR+3atWP//v1+h2OMSVCRipJqquoI9/tS\nEcmKR0AmNoJbHH322WekpKT4HZIxJkFFShiqisjJ7ncBqrnTgjOIz9yYR2cOWm5uLkOGDOGVV17h\n6aefpl+/fvZugjEmokgJwwbgmQjTnWMSkYmqBQsWkJ2dbe8lGGM8izRQT6c4xmFipE2bNkycONHv\nMIwxScQ6wTHGGFOAJQxlRG5uLh8G+h43xpiDYAlDGZCdnU27du0YPnw4+/bt8zscY0yS89K7agV3\nrOdH3OkmItLO6wFEpLuILBWRn0TkvjDLrxCReSIyX0S+FZFWJTuF8it07OWJEydSsaKXXk6MMaZo\nXu4iLwN5wNnAo8Cf7rxTittQRFKAF4EuwFrgBxGZpKpLglb7BThLVbeJSHdgOHBqic6iHFq+fDm9\nevWynlCNMVHnJWFor6onBV5wU9UtIlLJ4/7bActV9VcAERkLXAjkJwyqOjNo/e+BRh73Xa7VqVOH\ne++9l8svv9zeSzDGRJWXOoZc98kfyB+PIc/j/hsCq4Om17jzinIt8LGXHY8cCSkpzueWWyA93WNE\nZUR6ejp9+/a1RMEYE3VecgwvAO8D9UTkCaAXzuA9XhQ/bqhLRDoDfwPOCLd88ODB+d87derEpk2d\nuPNOGDrUmWejTxpjyrvMzEwyMzMPej9ex3xuAZzjTk4LqSOItN2pwGBV7e5OPwDkqerQkPVaAROA\n7qq6PMx+Co35/NRTsGmT87Msy87O5umnn2bUqFFUquS1BM8YY2I75nMTYAcw2f3scOd5MRs4WkQy\nRKQyziA/k8LsfwJwZbhEobwKbnHUtWtXa21kjIkbL3ebjzlQJFQVOAJYBhxX3Iaquk9EbgGmAinA\nG6q6RERudJe/BjwCpAOvuOXle1XVc3PYssjGXjbG+MnLCG7HB0+7Paze7PUAqvoJIUOBuglC4Pt1\nwHVe91fWZWVl0a1bN+sJ1RjjmxKXT6jqXBFpH4tgDJx44oksWrSIQw891O9QjDHlVLEJg4gMCJqs\nAJyM87KaiQERsUTBGOMrL408awZ9KuMM93lhLIMqL7Zt2+Z3CMYYU0jEHIP7YlstVR0QaT1TMoFR\n1d566y2WLFlC5cqV/Q7JGGPyFZljEJGKqrofOEOsBjRqsrKyaNu2LXPmzGH69OmWKBhjEk6kHMMs\nnPqEbGCiiIwDdrrLVFUnxDq4siR47OVnnnmGK6+80locGWMSUqSEIXDXqgpsxuldNZglDCXw888/\ns3DhQnsvwRiT8CIlDIeKyF3AgngFU5a1aNGC8ePH+x2GMcYUK1LCkAKkxisQY4wxiSFSwrBBVf8Z\nt0jKiNzcXCZOnMill17qdyjGGFMq1ll1FAVaHI0ZM4Y9e/b4HY4xxpRKpBxDl7hFkeSsxVH82HU1\nJjwvQyh4VWTCoKqbo3aUMmzFihVcdNFFNGnSxFocxUk0/wGMKQui/cBknfwfpHr16vHggw/Su3dv\ne5o1xpQJljAcpBo1atCnTx+/wzDGmKixymdjjDEFWMLgUVZWFhdffDG7d+/2OxRjjIkpSxiKERh7\nuVu3bvz1r3+lSpUqfodkTFJYvHgxbdu29TuMMqFXr15MmTIlbsezhCGCwHsJc+fOJTs724baNBFl\nZGRQvXp1UlNTadCgAf369WP79u0F1pkxYwZnn302tWrVIi0tjQsuuIAlS5YUWGf79u3ccccdNG3a\nlNTUVI466ijuvPNONm9OroaCDz/8MPfcc4/fYRyUX3/9lc6dO1OjRg1atGjBtGnTily3R48epKam\n5n+qVKlCq1at8pcH/32kpqbSvXv3Attv3LiRvn37kpaWRu3atbnyyivzl913330MHDgw+idYBEsY\nirBs2TK6devG3XffzaRJk6wZqimWiPDhhx+Sk5PDvHnzWLBgAY8//nj+8pkzZ+bnPNevX8+KFSto\n3bo1Z5xxBitWrACcHOo555zDkiVLmDp1Kjk5OcycOZO6desya9asmMW+b9++qO5v/fr1ZGZmctFF\nF5Vq+/3790c1ntK6/PLLadOmDVu2bGHIkCH06tWLTZs2hV33k08+IScnJ/9z+umn07t37/zlwX8f\nOTk5hXIAF198MYcffjirV69m48aNBRLVtm3bsn37dubMmRObEw2lqgn/ccIsaOhQ1XvuKTQ7qrZs\n2RLbA5gSC/e3kCgyMjJ02rRp+dP33HOPnnfeefnTHTp00JtvvrnQdj169NCrrrpKVVVHjBih9evX\n1x07dng+7sKFC7VLly5au3ZtrV+/vj755JOqqnr11VfrwIED89f78ssvtVGjRvnTTZs21aFDh+oJ\nJ5ygVapU0aFDh2qvXr0K7Pu2227T2267TVVV//jjD/3b3/6mhx12mDZs2FAHDhyo+/fvDxvT6NGj\n9dxzzy0w78knn9RmzZppamqqtmzZUt9///38ZaNGjdLTTz9d77zzTq1Tp44+/PDDumfPHh0wYIA2\nadJE69evrzfddJPu2rVLVVW3bt2qPXv21EMPPVTT09P1/PPP1zVr1ni+Zl4sW7ZMq1Spon/++Wf+\nvLPOOktfffXVYrddsWKFpqSk6MqVK/PnZWRk6Oeffx52/alTp2pGRkaR11NV9frrr9d//vOfYZcV\n9X/hzi/xPddyDBGkp6f7HYJJMuq+fLdmzRqmTJlC+/btAdi5cyczZ84M24dW7969+eyzzwD4/PPP\n6dGjB9WrV/d0vJycHLp06cJ5553H+vXrWb58Oeeccw7gPKEWV/Q5duxYPvnkE7Zt28Zll13Gxx9/\nzJ9//gk4T+3jxo3jiiuuAKB///5UrlyZn3/+maysLD799FNef/31sPtdsGABzZs3LzDvqKOO4ptv\nvmH79u0MGjSIK6+8kt9++y1/+axZs2jWrBm///47Dz74IPfddx/Lly9n3rx5LF++nLVr1/Loo48C\nkJeXx7XXXsuqVatYtWoV1apV45ZbbinyPM8//3zS09PDfi644IKw2yxatIgjjzySGjVq5M9r3bo1\nixYtinhNAcaMGcNZZ51FkyZNCsy/4oorqFevHt26dWP+/Pn587/77juaN2/O1VdfTd26dWnXrh1f\nf/11gW1btGjBvHnzij12VJQmNYn3hxjnGDZt2hSdHZmYC/e3UHB5dD6l0bRpU61Zs6ampqaqiOhF\nF12U/wS4evVqFRFdtmxZoe0++eQTrVSpkqqqdunSRR944AHPx3z77bf15JNPDrusf//+EXMMGRkZ\nOmrUqALbdOjQQceMGaOqqp9++qk2a9ZMVVU3bNigVapUyX9iDxy7c+fOYY99/fXX6/333x8x9hNP\nPFEnTpyoqk6OoUmTJvnL8vLytEaNGvrzzz/nz5sxY4YeccQRYfeVlZWl6enpEY9XUmPGjNFTTz21\nwLyHHnpI+/fvX+y2zZo109GjRxeYN2PGDN29e7fu3LlTn3zySW3QoIFu27ZNVZ3rJSI6cuRI3bdv\nn44dO1bT0tIK3JuGDx+uZ599dtjjFfV/geUYSi7Q4uikk05i586dxW9gEl60kobSEBEmTpzI9u3b\nyczM5IsvvmD27NmAk/usUKEC69evL7Td+vXrOfTQQwGoW7cu69at83zM1atXc+SRR5YuYKBx48YF\npvv27cs777wDwNtvv52fW1i5ciV79+7lsMMOy3/Svummm9i4cWPY/aanp5OTk1Ng3pgxYzjppJPy\nt1+4cGGBCvXgWDZu3MjOnTtp06ZN/vo9evTIL9/fuXMnN954IxkZGRxyyCF07NiRbdu25efYoqFm\nzZqFGg/88ccf1KpVK+J233zzDb/99hu9evUqMP+0006jSpUqVKtWjfvvv5+0tDSmT58OQLVq1Tji\niCO45pprSElJoU+fPjRu3Jhvv/02f/ucnBzS0tKidHaRlduEIbjF0Xfffec5626MF2eddRa33nor\n9913H+C8IX/aaafx7rvvFlr33XffzS/+6dKlC1OnTvX8oNKkSRN++eWXsMtq1KhRYD8bNmwotE5o\nUVOvXr3IzMxk7dq1fPDBB/Tt2xdwbtpVqlRh8+bNbN26la1bt7Jt2zYWLAg/jlerVq348ccf86dX\nrlzJDTfcwEsvvcSWLVvYunUrxx9/fIEbeXAsdevWpVq1aixevDj/eH/88Uf+jfqZZ57hxx9/ZNas\nWWzbto2vvvoquIShkNAWQ8Gfnj17ht3muOOO45dffskvWgOYN28exx13XNj1A0aPHs0ll1xS7D1F\nRPLjbd26ddjlwddkyZIlnHjiiRH3GTWlyWbE+0MUi5L27NmjjzzyiB566KE6ZswYzcvLK/lOjG/C\n/S0kitDK540bN2r16tX1u+++U1XVb775RmvUqKHPP/+8bt++Xbds2aIPPfSQpqen6/Lly1XV+fts\n27atdu/eXZcuXar79+/XTZs26ZAhQ/Tjjz8udMycnBw97LDD9LnnntPdu3fr9u3b9fvvv1dVpyL7\n2GOP1S1btuj69eu1ffv2hYqSguMN6NGjh3bp0qVQEdWFF16ot99+u27fvl3379+vy5cv16+++irs\ntdiwYYPWqVNH9+zZo6qqixYt0qpVq+qyZct03759OnLkSK1YsaK+8cYbquoUJXXo0KHAPm6//Xbt\n3bu3/v7776qqumbNGp06daqqqt57773ao0cP3b17t27evFkvuugiFZGIlbelceqpp+rdd9+tu3bt\n0vHjxxcq3gm1c+dOPeSQQ/TLL78sMH/VqlX6zTff6J49e3TXrl361FNPab169fIbuGzZskXT09N1\n9OjRum/fPh03bpzWqVNHN2/enL+PY445Rn/44Yewxy3q/wIrSvJm/fr1LF261N5LMDFXt25drr76\naoYOHQrAGWecwdSpU5kwYQKHH344GRkZzJs3j2+++YZmzZoBULlyZT7//HOOPfZYzj33XA455BDa\nt2/Pli1bOPXUUwsdo2bNmnz22WdMnjyZww47jGOOOYbMzEwA+vXrR+vWrcnIyKB79+5cdtllnv7e\n+/bty7Rp0/JzCwFjxowhNzeXli1bUrt2bS699NKwuRCA+vXrc/bZZ/PBBx8A0LJlSwYMGMBpp51G\ngwYNWLhwIR06dMhfP1xF+dChQznqqKM49dRTOeSQQzj33HPzcyF33HEHu3btom7dupx++un06NEj\nJv/LY8eOZfbs2dSuXZuHHnqI8ePHU6dOHQCmT59OamrBQS4/+OAD0tPT6dSpU4H5OTk5/OMf/6B2\n7do0atSITz/9lE8++SS/gUt6ejqTJk3i6aefJi0tjaeeeoqJEydSu3ZtAH744QdSU1M55ZRTon6O\n4YhGsUwuVkREQ+N86inYtMn5acqP4Oy3SWxLlizh6quvjun7F+VFr169uO666wq9FBdQ1P+FO7/E\nKab1rmqMiYkWLVpYohAl7733XlyPl1RFST//DK++6nxmzoy8bm5uLqNHj7anS2OMKaGkShhGj4bX\nX4fsbKhfH847L/x6gRZH7733njVDNcaYEkq6oqQLLoBHHgm/zMZeNsaYg5d0CUNR1qxZQ8+ePW3s\nZWOMOUhlJmGoV68egwYN4q9//avlEowx5iCUmYShcuXKXHzxxX6HYeLAEn5jYiumCYOIdAeeA1KA\n11V1aJh1ngd6ADuB/qqaFcuYTHKzVmbGxF7MWiWJSArwItAdaAlcLiItQtY5DzhKVY8GbgBeKWp/\n6enOy2x//JFFjx49CnVuVV4E3mo1di2C2bU4wK7FwYtlc9V2wHJV/VVV9wJjgQtD1rkAGA2gqt8D\naSJSP9zOli7N5bbbBvHWW93o27dvoVfRywv7oz/ArsUBdi0OsGtx8GJZlNQQWB00vQZo72GdRsBv\nIevRtWtba3FkjDFxEMuEwWthcGhNYtjtBgwYYJ3eGWNMHMSsEz0RORUYrKrd3ekHgLzgCmgReRXI\nVNWx7vRSoKOq/hayL6txNMaYUki0TvRmA0eLSAawDugDXB6yziTgFmCsm5D8EZooQOlOzBhjTOnE\nLGFQ1X0icgswFae56huqukREbnSXv6aqH4vIeSKyHNgBXBOreIwxxniTFOMxGGOMiZ+E6l1VRLqL\nyFIR+UlE7itinefd5fNE5KR4xxgvxV0LEbnCvQbzReRbEWnlR5zx4OXvwl2vrYjsE5Ey+Qq8x/+P\nTiKSJSILRSQzziHGjYf/j7oiMkVEst1r0d+HMONCREaKyG8iEn4Abkpx3yzNeKCx+OAUNy0HMoBK\nQDbQImSd84CP3e/tge/8jtvHa3EacIj7vXt5vhZB630BfAhc4nfcPv1NpAGLgEbudF2/4/bxWgwG\nngxcB2AzUNHv2GN0Pc4ETgIWFLG8xPfNRMoxRPWFuCRX7LVQ1Zmqus2d/B7n/Y+yyMvfBcCtwHvA\nxngGF0derkNfYLyqrgFQ1U1xjjFevFyL9UAt93stYLOq7otjjHGjqtOBrRFWKfF9M5EShnAvuzX0\nsE5ZvCF6uRbBrgU+jmlE/in2WohIQ5wbQ6BLlbJYceblb+JooLaIfCkis0WkX9yiiy8v12IEcJyI\nrAPmAbfHKbZEVOL7ZiL1rhrVF+KSnOdzEpHOwN+AM2IXjq+8XIvngPtVVcV5A7IsNm/2ch0qAScD\n5wDVgZki8p2q/hTTyOLPy7V4EMhW1U4i0gz4TERaq2pOjGNLVCW6byZSwrAWaBw03RgnZYu0TiN3\nXlnj5VrgVjiPALqraqSsZDLzci3a4LwLA055cg8R2auqk+ITYlx4uQ6rgU2qugvYJSJfA62BspYw\neLkWpwNDAFT1ZxFZATTHeb+qvCnxfTORipLyX4gTkco4L8SF/mNPAq6C/Derw74QVwYUey1EpAkw\nAbhSVZf7EGO8FHstVPVIVT1CVY/AqWf4exlLFMDb/8dEoIOIpIhIdZyKxsVxjjMevFyLpUAXALc8\nvTnwS1yjTBwlvm8mTI5B7YW4fF6uBfAIkA684j4p71XVdn7FHCser0WZ5/H/Y6mITAHmA3nACFUt\ncwmDx7+JJ4BRIjIP5wH4XlXd4lvQMSQi7wAdgboishoYhFOsWOr7pr3gZowxpoBEKkoyxhiTACxh\nMMYYU4AlDMYYYwqwhMEYY0wBljAYY4wpwBIGY4wxBVjCUE6IyH63O+bAp0mEdf+MwvHeFJFf3GPN\ncV+sKek+RojIse73B0OWfXuwMbr7CVyX+SIyQURqFrN+axHpEY1je4zvcxFJdb8X271yMfs6X0Tm\nul1RLxKRG6Ic6z9F5Bz3+5nuMeaKyOEiMs6d7+n6ichtZbivp4Rn7zGUEyKSo6qp0V43wj5GAZNV\ndYKInAs8raqtD2J/Bx1TcfsVkTdxui5+JsL6/YE2qnprlOOoGNr7p4icjdOF+M3u9JnAn8AYVT2h\nhPuvBPwKtFXVde70Ear6Y1ROoPDxXgWmq+p/Q+b3x8P1cxPDaWXxpc1kYDmGckpEarhPo3Pcp+UL\nwqxzmIh87T5RLxCRDu78riIyw932XRGpUdRh3J/TgaPcbe9y97VARG4PiuUj90l2gYhc6s7PFJE2\nIvJ/QDU3jv+4y/50f44VkfOCYn5TRC4WkQoi8i8RmSXO4CReno5nAs3c/bRzz3GuOAMhHeN2v/Ao\n0MeN5VI39pEi8r27bqHr6O7vX+65zReR3u68TiIyXUQm4oyjEKovTjcXgKfulSNJxenpYIu7r72B\nRMG9Zq+KyA8iskxEerrzU4q6hiJyn3su2SLyRNB+LhGRa4FLgcdE5D8i0tQ990pB12+uiPQWkR9F\npK67fQURWS4iddzO7jaLyHGlPF9zMPweZMI+8fkA+4As9zMepyuBVHdZXeCnoHVz3J8DgAfd7xWA\nmu66XwHV3Pn3AQ+HOd4o3AFzcG4SM3F6/pwPVANqAAuBE4FLgOFB29Zyf34JnBwcU5gYLwLedL9X\nBlYBVYAbgIfc+VWAH4CMMHEG9pPiXpd/uNOpQIr7vQvwnvv9auD5oO2fAK5wv6cBy4DqIce4BPgU\nJ6GsB6wEGgCdcHIATYv4nS0BaofMy6CIAVk8/A2MAH4D3sZJdAIlBqM4MJDLUTid8RV5DYEewLdA\n1cB5B+3n4jDf82MOc/0eAW53v3cFxgUt+ydOv1e+//+Ut0/C9JVkYm6XquYP6ec+vT3pFk/kAYeL\nSD1V/T1om1nASHfdD1R1noh0AloCM8Tpo6kyMCPM8QT4l4gMBH7HGTPiXGCCOr1/IiITcEafmgI8\n7eYMPlTVb0pwXlOAf7tP8z2Ar1R1j4h0BU4QkV7uerVwbnq/hmxfTUSycPqs/xV41Z2fBowRkaNw\nuigO/K+EduvdFfiLiNztTlfB6clyWdA6ZwBvq3O3+11EvgLaAtuBWaq6sohzO1yj2L+Pql4vIv/G\nSejuxvl9BPrNedddZ7mI/AIc655b6DU8Gqdb75Gqutvd5o8iDhmu+/PQ6zcSJ1f0b5zu40cFLVsH\nHFmSczTRYQlD+XUFztP/yaq6X5xuiasGr6Cq092E43zgTREZhlOU8Zmq9i1m/wrcraoTAjNEpAsF\nbwriHEZ/Emcc2p7A4yIyTVUf83ISqrpbnLGNuwG9gXeCFt+iqp8Vs4tdqnqSiFTD6ZTtQuB94DGc\nMu6/ikhTIDPCPi7W4sc8KKo//B3FbOeZiKRwoFvpiao6OHQdVV0ILHSL5FZQdIdqgfgKXUMR6UaU\nxrxQ1TXiVKifjZNYXh58KLyNvWCizOoYyq9awO9uotAZaBq6gjgtlzaq6uvA6zjjyn4HnCHO4CeB\n+oGjizhG6M1jOnCRiFRz6yUuAqaLyGHAbnUqKp92jxNqr4gU9SDzP5ynzUDuA5yb/D8C27h1BNWL\n2B43F3MbMEScrFAtnCdWKHjz3I5TzBQw1d0O9zjhYp+OU65eQUQOBc7CyY0Vd3NdJyJ1ilkn+Bz2\nq+pJ7mdw8DL399QpaNZJHMg9CXCpOJrhPKUvpehr+BlwjZuYIiLpXmOk8PUD52/rLeBdN1cVcBiF\nc3gmDixhKD9Cn7z+C5wiIvOBfjjl2aHrdgayRWQuztP4v9UZR7g/8I44XRrPwOnrvthjqmoW8CbO\nTfE7nG6h5wEnAN+7RTqPAI+H2ddwYH6g8jlk35/i3Gw/0wMte17HGYtgrjjNO18hfA45fz+qmo0z\nyHxv4Cmcora5OPUPgfW+BFoGKp9xchaV3IrYhTjl4gUPoPo+Tt3KPGAacI9bZKeh1yjEN8ApgQlx\nuleeARwjIqtFpCTdzgtwj4gsda/zIJzfY+AarML5vXwM3KiquYS/himqOhWnj//Z7r4GFHFMDfM9\n+Pr1dudNxqlzCi5GAmds5+klOEcTJdZc1ZgE5T7h91HVv8f4OPlNi2N5nAjHPwV4RlU7Bs2rhVOU\n19aPmMo7yzEYk6BUNRNnpLKov7+RKETkfpxR9x4IWdQfp0La+MByDMYYYwqwHIMxxpgCLGEwxhhT\ngGgjjZ4AAAAgSURBVCUMxhhjCrCEwRhjTAGWMBhjjCnAEgZjjDEF/D+QyBBMkrYAqQAAAABJRU5E\nrkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10d826048>"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the area under ROC curve is 0.756 which is very similar to the accuracy (0.732). However the ROC-AUC score of a random model is expected to 0.5 on average while the accuracy score of a random model depends on the class imbalance of the data. ROC-AUC can be seen as a way to callibrate the predictive accuracy of a model against class imbalance."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We previously decided to randomly split the data to evaluate the model on 20% of held-out data. However the location randomness of the split might have a significant impact in the estimated accuracy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=1)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "0.67039106145251393"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=2)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "0.66480446927374304"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So instead of using a single train / test split, we can use a group of them and compute the min, max and mean scores as an estimation of the real test score while not underestimating the variability:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(logreg, features_array, target, cv=5)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "array([ 0.63128492,  0.68715084,  0.70224719,  0.73033708,  0.71751412])"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "(0.63128491620111726, 0.69370682962933028, 0.7303370786516854)"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`cross_val_score` reports accuracy by default be it can also be used to report other performance metrics such as ROC-AUC or f1-score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(logreg, features_array, target, cv=5,\n",
      "                         scoring='roc_auc')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "(0.61093544137022393, 0.72123181651091728, 0.78776737967914434)"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Compute cross-validated scores for other classification metrics ('precision', 'recall', 'f1', 'accuracy'...).\n",
      "\n",
      "- Change the number of cross-validation folds between 3 and 10: what is the impact on the mean score? on the processing time?\n",
      "\n",
      "Hints:\n",
      "\n",
      "The list of classification metrics is available in the online documentation:\n",
      "\n",
      "  http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\n",
      "  \n",
      "You can use the `%%time` cell magic on the first line of an IPython cell to measure the time of the execution of the cell. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "More feature engineering and richer models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us now try to build richer models by including more features as potential predictors for our model.\n",
      "\n",
      "Categorical variables such as `data.Embarked` or `data.Sex` can be converted as boolean indicators features also known as dummy variables or one-hot-encoded features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.get_dummies(data.Sex, prefix='Sex').head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Sex_male</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "   Sex_female  Sex_male\n",
        "0           0         1\n",
        "1           1         0\n",
        "2           1         0\n",
        "3           1         0\n",
        "4           0         1"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.get_dummies(data.Embarked, prefix='Embarked').head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "   Embarked_C  Embarked_Q  Embarked_S\n",
        "0           0           0           1\n",
        "1           1           0           0\n",
        "2           0           0           1\n",
        "3           0           0           1\n",
        "4           0           0           1"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can combine those new numerical features with the previous features using `pandas.concat` along `axis=1`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features = pd.concat([data.get(['Fare', 'Pclass', 'Age']),\n",
      "                           pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                           pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
      "                          axis=1)\n",
      "rich_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Sex_male</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
        "0   7.2500       3   22           0         1           0           0   \n",
        "1  71.2833       1   38           1         0           1           0   \n",
        "2   7.9250       3   26           1         0           0           0   \n",
        "3  53.1000       1   35           1         0           0           0   \n",
        "4   8.0500       3   35           0         1           0           0   \n",
        "\n",
        "   Embarked_S  \n",
        "0           1  \n",
        "1           0  \n",
        "2           1  \n",
        "3           1  \n",
        "4           1  "
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By construction the new `Sex_male` feature is redundant with `Sex_female`. Let us drop it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features_no_male = rich_features.drop('Sex_male', 1)\n",
      "rich_features_no_male.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S\n",
        "0   7.2500       3   22           0           0           0           1\n",
        "1  71.2833       1   38           1           1           0           0\n",
        "2   7.9250       3   26           1           0           0           1\n",
        "3  53.1000       1   35           1           0           0           1\n",
        "4   8.0500       3   35           0           0           0           1"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us not forget to imput the median age for passengers without age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features_final = rich_features_no_male.fillna(rich_features_no_male.dropna().median())\n",
      "rich_features_final.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S\n",
        "0   7.2500       3   22           0           0           0           1\n",
        "1  71.2833       1   38           1           1           0           0\n",
        "2   7.9250       3   26           1           0           0           1\n",
        "3  53.1000       1   35           1           0           0           1\n",
        "4   8.0500       3   35           0           0           0           1"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can finally cross-validate a logistic regression model on this new data an observe that the mean score has significantly increased:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "scores = cross_val_score(logreg, rich_features_final, target, cv=5, scoring='accuracy')\n",
      "print(\"Logistic Regression CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic Regression CV scores:\n",
        "min: 0.770, mean: 0.786, max: 0.810\n",
        "CPU times: user 32.9 ms, sys: 8.14 ms, total: 41 ms\n",
        "Wall time: 22.2 ms\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- change the value of the parameter `C`. Does it have an impact on the score?\n",
      "\n",
      "- fit a new instance of the logistic regression model on the full dataset.\n",
      "\n",
      "- plot the weights for the features of this newly fitted logistic regression model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04A_plot_logistic_regression_weights.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training Non-linear models: ensembles of randomized trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` also implement non linear models that are known to perform very well for data-science projects where datasets have not too many features (e.g. less than 5000).\n",
      "\n",
      "In particular let us have a look at Random Forests and Gradient Boosted Trees:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "scores = cross_val_score(rf, rich_features_final, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "print(\"Random Forest CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest CV scores:\n",
        "min: 0.788, mean: 0.805, max: 0.831\n",
        "CPU times: user 106 ms, sys: 20.5 ms, total: 126 ms\n",
        "Wall time: 603 ms\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                subsample=.8, max_features=.5)\n",
      "scores = cross_val_score(gb, rich_features_final, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "print(\"Gradient Boosted Trees CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Gradient Boosted Trees CV scores:\n",
        "min: 0.771, mean: 0.818, max: 0.843\n",
        "CPU times: user 67.3 ms, sys: 20.1 ms, total: 87.4 ms\n",
        "Wall time: 364 ms\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both models seem to do slightly better than the logistic regression model on this data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Change the value of the learning_rate and other `GradientBoostingClassifier` parameter, can you get a better mean score?\n",
      "\n",
      "- Would treating the `PClass` variable as categorical improve the models performance?\n",
      "\n",
      "- Find out which predictor variables (features) are the most informative for those models.\n",
      "\n",
      "Hints:\n",
      "\n",
      "Fitted ensembles of trees have `feature_importances_` attribute that can be used similarly to the `coef_` attribute of linear models."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04B_more_categorical_variables.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04C_feature_importance.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automated parameter tuning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of changing the value of the learning rate manually and re-running the cross-validation, we can find the best values for the parameters automatically (assuming we are ready to wait):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, subsample=.8)\n",
      "\n",
      "params = {\n",
      "    'learning_rate': [0.05, 0.1, 0.5],\n",
      "    'max_features': [0.5, 1],\n",
      "    'max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(gb, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(rich_features_final, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 631 ms, sys: 33.3 ms, total: 664 ms\n",
        "Wall time: 4.72 s\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us sort the models by mean validation score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(gs.grid_scores_, key=lambda x: x.mean_validation_score, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "[mean: 0.87467, std: 0.02466, params: {'learning_rate': 0.1, 'max_depth': 4, 'max_features': 1},\n",
        " mean: 0.87234, std: 0.02559, params: {'learning_rate': 0.05, 'max_depth': 5, 'max_features': 1},\n",
        " mean: 0.87224, std: 0.02657, params: {'learning_rate': 0.5, 'max_depth': 3, 'max_features': 0.5},\n",
        " mean: 0.87217, std: 0.02492, params: {'learning_rate': 0.1, 'max_depth': 4, 'max_features': 0.5},\n",
        " mean: 0.87189, std: 0.02115, params: {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 0.5},\n",
        " mean: 0.87173, std: 0.02637, params: {'learning_rate': 0.1, 'max_depth': 5, 'max_features': 0.5},\n",
        " mean: 0.87055, std: 0.02934, params: {'learning_rate': 0.05, 'max_depth': 5, 'max_features': 0.5},\n",
        " mean: 0.86732, std: 0.02172, params: {'learning_rate': 0.05, 'max_depth': 4, 'max_features': 1},\n",
        " mean: 0.86720, std: 0.02899, params: {'learning_rate': 0.05, 'max_depth': 4, 'max_features': 0.5},\n",
        " mean: 0.86656, std: 0.02496, params: {'learning_rate': 0.5, 'max_depth': 3, 'max_features': 1},\n",
        " mean: 0.86611, std: 0.01934, params: {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 1},\n",
        " mean: 0.86496, std: 0.02858, params: {'learning_rate': 0.1, 'max_depth': 5, 'max_features': 1},\n",
        " mean: 0.86392, std: 0.02674, params: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 0.5},\n",
        " mean: 0.85853, std: 0.01979, params: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 1},\n",
        " mean: 0.85461, std: 0.02936, params: {'learning_rate': 0.5, 'max_depth': 4, 'max_features': 0.5},\n",
        " mean: 0.84942, std: 0.02146, params: {'learning_rate': 0.5, 'max_depth': 4, 'max_features': 1},\n",
        " mean: 0.84767, std: 0.02230, params: {'learning_rate': 0.5, 'max_depth': 5, 'max_features': 1},\n",
        " mean: 0.83840, std: 0.03602, params: {'learning_rate': 0.5, 'max_depth': 5, 'max_features': 0.5}]"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "0.87467494296148274"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{'learning_rate': 0.1, 'max_depth': 4, 'max_features': 1}"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should note that the mean scores are very close to one another and almost always within one standard deviation of one another. This means that all those parameters are quite reasonable. The only parameter of importance seems to be the `learning_rate`: 0.5 seems to be a bit too high."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Avoiding data snooping with pipelines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When doing imputation in pandas, prior to computing the train test split we use data from the test to improve the accuracy of the median value that we impute on the training set. This is actually cheating. To avoid this we should compute the median of the features on the training fold and use that median value to do the imputation both on the training and validation fold for a given CV split.\n",
      "\n",
      "To do this we can prepare the features as previously but without the imputation: we just replace missing values by the -1 marker value:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = pd.concat([data.get(['Fare', 'Age']),\n",
      "                      pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                      pd.get_dummies(data.Pclass, prefix='Pclass'),\n",
      "                      pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
      "                     axis=1)\n",
      "features = features.drop('Sex_male', 1)\n",
      "\n",
      "# Because of the following bug we cannot use NaN as the missing\n",
      "# value marker, use a negative value as marker instead:\n",
      "# https://github.com/scikit-learn/scikit-learn/issues/3044\n",
      "features = features.fillna(-1)\n",
      "features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Pclass_1</th>\n",
        "      <th>Pclass_2</th>\n",
        "      <th>Pclass_3</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "      Fare  Age  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  \\\n",
        "0   7.2500   22           0         0         0         1           0   \n",
        "1  71.2833   38           1         1         0         0           1   \n",
        "2   7.9250   26           1         0         0         1           0   \n",
        "3  53.1000   35           1         1         0         0           0   \n",
        "4   8.0500   35           0         0         0         1           0   \n",
        "\n",
        "   Embarked_Q  Embarked_S  \n",
        "0           0           1  \n",
        "1           0           0  \n",
        "2           0           1  \n",
        "3           0           1  \n",
        "4           0           1  "
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use the `Imputer` transformer of scikit-learn to find the median value on the training set and apply it on missing values of both the training set and the test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(features.values, target, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import Imputer\n",
      "\n",
      "imputer = Imputer(strategy='median', missing_values=-1)\n",
      "\n",
      "imputer.fit(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "Imputer(axis=0, copy=True, missing_values=-1, strategy='median', verbose=0)"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The median age computed on the training set is stored in the `statistics_` attribute."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputer.statistics_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "array([ 14.5,  29. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   1. ])"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imputation can now happen by calling  the transform method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_imputed = imputer.transform(X_train)\n",
      "X_test_imputed = imputer.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_train == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_train_imputed == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_test == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_test_imputed == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use a pipeline that wraps an imputer transformer and the classifier itself:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "imputer = Imputer(strategy='median', missing_values=-1)\n",
      "\n",
      "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                        subsample=.8, max_features=.5)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', classifier),\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, features.values, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy', )\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.792134831461 0.813751003179 0.842696629213\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The mean cross-validation is slightly lower than we used the imputation on the whole data as we did earlier although not by much. This means that in this case the data-snooping was not really helping the model cheat by much.\n",
      "\n",
      "Let us re-run the grid search, this time on the pipeline. Note that thanks to the pipeline structure we can optimize the interaction of the imputation method with the parameters of the downstream classifier without cheating:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "params = {\n",
      "    'imp__strategy': ['mean', 'median'],\n",
      "    'clf__max_features': [0.5, 1],\n",
      "    'clf__max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(pipeline, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 398 ms, sys: 30.1 ms, total: 428 ms\n",
        "Wall time: 2.98 s\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(gs.grid_scores_, key=lambda x: x.mean_validation_score, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "[mean: 0.87225, std: 0.02833, params: {'imp__strategy': 'mean', 'clf__max_depth': 3, 'clf__max_features': 0.5},\n",
        " mean: 0.87182, std: 0.02588, params: {'imp__strategy': 'median', 'clf__max_depth': 4, 'clf__max_features': 0.5},\n",
        " mean: 0.86919, std: 0.02742, params: {'imp__strategy': 'mean', 'clf__max_depth': 4, 'clf__max_features': 0.5},\n",
        " mean: 0.86531, std: 0.03043, params: {'imp__strategy': 'median', 'clf__max_depth': 3, 'clf__max_features': 0.5},\n",
        " mean: 0.86307, std: 0.02605, params: {'imp__strategy': 'median', 'clf__max_depth': 5, 'clf__max_features': 0.5},\n",
        " mean: 0.86213, std: 0.01998, params: {'imp__strategy': 'median', 'clf__max_depth': 3, 'clf__max_features': 1},\n",
        " mean: 0.85916, std: 0.02773, params: {'imp__strategy': 'median', 'clf__max_depth': 4, 'clf__max_features': 1},\n",
        " mean: 0.85908, std: 0.01896, params: {'imp__strategy': 'mean', 'clf__max_depth': 5, 'clf__max_features': 1},\n",
        " mean: 0.85632, std: 0.02306, params: {'imp__strategy': 'mean', 'clf__max_depth': 4, 'clf__max_features': 1},\n",
        " mean: 0.85544, std: 0.02490, params: {'imp__strategy': 'mean', 'clf__max_depth': 5, 'clf__max_features': 0.5},\n",
        " mean: 0.85467, std: 0.02354, params: {'imp__strategy': 'median', 'clf__max_depth': 5, 'clf__max_features': 1},\n",
        " mean: 0.84892, std: 0.02833, params: {'imp__strategy': 'mean', 'clf__max_depth': 3, 'clf__max_features': 1}]"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "0.87224910073903605"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(y_test, gs.predict_proba(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x107ca0e80>"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "{'imp__strategy': 'mean', 'clf__max_depth': 3, 'clf__max_features': 0.5}"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this search we can conclude that the imputation by the 'mean' strategy is generally a slightly better imputation strategy when training a GBRT model on this data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further integrating sklearn and pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper tool for better sklearn / pandas integration: https://github.com/paulgb/sklearn-pandas by making it possible to embed the feature construction from the raw dataframe directly inside a pipeline."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Credits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thanks to:\n",
      "\n",
      "- Kaggle for setting up the Titanic challenge.\n",
      "\n",
      "- This blog post by Philippe Adjiman for inspiration:\n",
      "\n",
      "http://www.philippeadjiman.com/blog/2013/09/12/a-data-science-exploration-from-the-titanic-in-r/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    }
   ],
   "metadata": {}
  }
 ]
}